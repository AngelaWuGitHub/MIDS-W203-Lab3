---
title: "Lab 3 (Bhuvnesh Sharma, Weixin Wu)"
author: "Bhuvnesh Sharma, Weixin Wu"
date: "March 22, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(lmtest)
library(sandwich)
library(car)
library(stargazer)
library(effsize)
library(olsrr)
```

```{r}

```

# Introduction

Crime is huge menace in the society, there have been many attempts in past to reduce crime rates within communities in North Carolina. Traditional politicians and conventional approach has assumed that tough on crime is an effective tool to curb crime. Being tough on crime is regularly misunderstood as longer and mandatory prison sentences. This misguided strategy can lead to state’s higher investment on prison infrastructure and also make laws which can promote mandatory prison sentences appear as effective crime fighting tool. The goal of this study is to uncover the real facts around the crime rates within North Carolina to develop effective state policy around to reduce crime rates. Key motivation of the report discover the real drivers and instruments which the policy makers can use and have meaningful impact on crime. Study intends to empower the state politicians , key legislative leaders with key facts which have been based on data and not on conventional empirical narratives.
Study intends to discover key variables which have major impact on crime rates in North Carolina . This information would be critical for voters to understand so that they can make an informed decision on a important election issue.
The main research question we want to answer is whether an increase in effective policing and conviction reduces crime rate.

# Data Cleansing

```{r}
crimeData <- read.csv("crime_v2.csv")
summary(crimeData)
```

As shown in the summary table, there are 6 NA's in every variable. 
After reviewing the data, we found that all NA's are in 6 rows, so we removed those rows as they did not provide any information.
```{r}
crimeData2 <- crimeData[complete.cases(crimeData),]
```

Variable 'prbconv' was incorrectly displayed as a text field. We converted it to numermic.
```{r}
crimeData2 <- transform(crimeData2, prbconv = as.numeric(as.character(prbconv)))
summary(crimeData2$prbconv)
```
Usually the probability variable should be bound between 0 and 1.
However, there is one observation with 'prbarr' (probability of arrest) higher than 1, 
and 10 observations with 'prbconv' (probability of conviction) higher than 1.
```{r}
nrow(crimeData2[which(crimeData2$prbarr>1),])
nrow(crimeData2[which(crimeData2$prbconv>1),])
```
Variable 'prbarr' is defined as the ratio of arrests to offenses. 
One possible explanation for 'prbarr' being greater than 1 is that 
multiple people who convicted a single crime together is counted as one conviction but multiple arrests.   
Variable 'prbconv' is defined as the ratio of convictions to arrests.
One possible explanation for 'prbconv' being greater than 1 is that 
one person who is convicted of multiple crimes but only arrested once.   
Without further information on the variables, we could not conclude whether these values are invalid.
So we left those observations in the data.

Variable 'pctmin80' (percent of minority in 1980) is expressed as percentages. 
We converted it into decimals to be consistent with variable 'pctymle' (percent of young male).
```{r}
crimeData2$pctmin80_2 <- crimeData2$pctmin80/100
```
The max value of variable 'wser' (weekly wage of service industry) is significantly higher than its third quartile.
The histogram below shows that the max value (2177.068) is significantly higher than the rest of values.
```{r}
par(mar=c(4, 2, 2, 2))
hist(crimeData2$wser, main="Histogram of Weekly Wage in Service Industry",
     xlab = "Weekly Wage of Services" , col = "royalblue1")
crimeData2[which(crimeData2$wser>2000),]
```
We examined County 185, whose wser is 2177.068.
We noticed that most other weekly wage variables for County 185 are below the means.
You would expect that a richer county would have weekly wage in multiple industries to be higher than the average.
So it's very unlikely for a county to have lower than average weekly wage on constructure, transportation, retail, finance, etc. 
but extremely high weekly wage on the service industry.

In addition, an average weekly wage of 2177.068 in 1987 is an unreasonable value.
So we believed 2177.068 is erroneous.
We removed this observation from the data.
```{r}
crimeData2 <- crimeData2[which(crimeData2$wser<2000),]
```

# Exploratory Data Analysis

## Crimes committed per person (crmrte)

The distribution of crime rate is skewed to the right, so we considered taking the log of crime rate.
After the log transformation, the distribution of crmrte_log is closer to normal.
Semilogarithmic form is interpretable later in modeling: 
it tells us what's the percentage change in crime rate in response to a unit change in explantory variables.
Our target variable is crmrte_log.
```{r}
par(mfrow=c(1,2), oma=c(0, 0, 2, 0))
par(mar=c(2, 2, 2, 2))
hist(crimeData2$crmrte, main="",xlab = "Crime Rate" , col = "royalblue1")
crimeData2$crmrte_log = log(crimeData2$crmrte)
hist(crimeData2$crmrte_log, main="", xlab = "Log of Crime Rate", col = "royalblue1")
mtext("Distributions of Crime Rate and Log Crime Rate", outer=TRUE, cex = 1.2, font=2)
```

## Probability of arrest (prbarr)

The scatter plot of crmrte vs. prbarr on the left shows an exponential decay trend.

In addition, the variation of crmrte decreases substantially as prbarr increases. 
We took the log of crime rate, and then re-graph the scatter plot (shown on the right).
The scatter plot of crmrte_log vs. prbarr indicates a more linear relationship 
and the variation of crmrte_log does not vary as much with prbarr.
The correlation coefficient further supports the transformation.  

* The correlation between crmrte and prbarr is -0.41  
* The correlation between crmrte_log and prbarr is -0.50  

In addition, we noticed a leveraged data point in the graph, that's County 115. 
County 115 has significantly higher probability of arrest than all other counties.
If we removed County 115 from the data, the correlation coefficient reduced from -0.50 to -0.39.
This indicates that County 115 could be an infludential observation. 
Later when building the model, we will calculate Cook's distance to confirm that County 15 is an influential observation 
and also address the impact of influential observations to parameter estimates.
```{r}
par(mfrow=c(1,3))
par(mar=c(4, 2, 2, 2))
plot(crimeData2$prbarr, crimeData2$crmrte , main = "Prob of arrest & Crime rate" , 
     xlab = "Prob of Arrest",ylab = "Crime Rate",col="royalblue1")
plot(crimeData2$prbarr, crimeData2$crmrte_log, main = "Prob of arrest & Log crime rate" , 
     xlab = "Prob of Arrest",ylab = "Log of Crime Rate",col="royalblue1")
cor(crimeData2$prbarr, crimeData2$crmrte)
cor(crimeData2$prbarr, crimeData2$crmrte_log)
plot(crimeData2$prbarr, crimeData2$crmrte,main = "Prob of arrest & Log crime rate" , 
     xlab = "Prob of Arrest",ylab = "Log of Crime Rate",col="royalblue1")
text(crimeData2$prbarr, crimeData2$crmrte, labels = crimeData2$county, cex=0.7, pos=3,col = "red")
crimeData3 <- crimeData2[which(crimeData2$county!=115),]
cor(crimeData3$prbarr, crimeData3$crmrte_log)
```


## Probability of conviction (prbconv)

Similar to prbarr, the scatter plot of crmrte vs. prbconv on the left shows an exponential decay trend.

In addition, the variation of crmrte decreases substantially as prbconv increases. 
We took the log of crime rate, and then re-graph the scatter plot (shown on the right).
The scatter plot of crmrte_log vs. prbconv indicates a more linear relationship 
and the variation of crmrte_log does not vary as much with prbconv
The correlation coefficient further supports the transformation.  

* The correlation between crmrte and prbarr is -0.37  
* The correlation between crmrte_log and prbarr is -0.41
```{r}
par(mfrow=c(1,2))
par(mar=c(4, 2, 2, 2))
plot(crimeData2$prbconv, crimeData2$crmrte,main = "Prob of conv & Crime rate" , 
     xlab = "Prob of Conviction",ylab = "Crime Rate",col="royalblue1")
plot(crimeData2$prbconv, crimeData2$crmrte_log,main = "Prob of conv & Log crime rate" ,
     xlab = "Prob of Conviction",ylab = "Log of Crime Rate",col="royalblue1")
cor(crimeData2$prbconv, crimeData2$crmrte)
cor(crimeData2$prbconv, crimeData2$crmrte_log)
```


## Probability of prison (prbpris) | Average sentence days (avgsen)

Neither scatter plots below (prbpris vs. crmrte_log, avgsen vs. crmrte_log) shows obvious relationships.
The correlation coefficients are only 0.03 and -0.08 respectively.
```{r}
par(mfrow=c(1,2))
par(mar=c(4, 2, 2, 2))
plot(crimeData2$prbpris, crimeData2$crmrte_log,main = "Prob of prison & Log crime rate" , 
     xlab = "Prob of Prison",ylab = "Log of Crime Rate",col="royalblue1")
plot(crimeData2$avgsen, crimeData2$crmrte_log,main = "Avg sent & Log crime rate" , 
     xlab = "Average Sentence",ylab = "Log of Crime Rate",col="royalblue1")
cor(crimeData2$prbpris, crimeData2$crmrte_log)
cor(crimeData2$avgsen, crimeData2$crmrte_log)
```


## Police per capita (polpc)

Similar to probabilities of arrest and conviction, 
we observed a linear relationship between crime rate and policy per capita in the scatter plot below.
The scatter plot also shows that County 115 has significantly higher police per capital than any other counties, 
County 115 is a highly leveraged observation. 

In addition, the variation of crmrte increases as prbconv increases, which justifies taking the log of crmrte.
The correlation between crmrte_log and polpc (after removing County 115) is 0.45.   
We also noticed that the distribution of polpc is highly skewed to the right, so we took the log of polpc.
The correlation coefficient (after removing County 115) increased from 0.45 to 0.54.
```{r}
par(mfrow=c(2,2))
par(mar=c(2, 2, 2, 2))
plot(crimeData2$polpc, crimeData2$crmrte,main = "Polpc & Crime Rate" , 
     xlab = "Police per capita",ylab = "Crime Rate",col="royalblue1")
plot(crimeData2$polpc, crimeData2$crmrte,main = "Polpc & Crime Rate" , 
     xlab = "Police per capita",ylab = "Crime Rate",col="royalblue1")
text(crimeData2$polpc, crimeData2$crmrte, labels = crimeData2$county, cex=0.7, pos=3,col = "red")
plot(crimeData3$polpc, crimeData3$crmrte_log,main = "Polpc & Log Crime Rate" , 
     xlab = "Police per capita",ylab = "Log of Crime Rate",col="royalblue1")
cor(crimeData3$polpc, crimeData3$crmrte_log)
hist(crimeData2$polpc, main="Histogram of Police per Capita",
     xlab = "Police per capita" , col = "royalblue1")
crimeData2$polpc_log <- log(crimeData2$polpc)
crimeData3 <- crimeData2[which(crimeData2$county!=115),]
cor(crimeData3$polpc_log, crimeData3$crmrte_log)
```


## People per square mile (density) | If in SMSA (urban)

The histogram shows the distribution of density is highly skewed to the right, so we took the log of density.
The scatter plot shows County 173 is highly leveraged as it has much lower population density than other counties.
Removing County 173 significantly increases correlation coefficient from 0.49 to 0.68.
The correlation between density and crmrte_log (without County 173) is 0.63, 
which is lower than the correlation between density_log and crmrte_log (without County 173) of 0.68.
This further confirms that log of density has a stronger linear relationship with log of crime rate than density does.   
Urban is a binary variable. 

The box plot shows that the the mean and interquartile range of density is significantly different 
depending on whether county is in urban area or not.
Log of density is highly correlated with urban with a correlation coefficient of 0.66. 
When building the model, we should avoid putting both variables in the model for two reasons:  

1. Adding the second variable doesn't explain much additional variation of the response variable   
2. High correlation can greatly increase the standard errors of parameter estimates
```{r}
par(mfrow=c(2,2))
par(mar=c(4, 2, 2, 2))
hist(crimeData2$density, main="Histogram of People per Square Mile",
     xlab = "People per Square Mile / Density " , col = "royalblue1")
crimeData2$density_log <- log(crimeData2$density)
plot(crimeData2$density_log, crimeData2$crmrte_log,main = "Log Density & Crime Rate" , 
     xlab = "Log of Density",ylab = "Log of Crime Rate",col="royalblue1")
plot(crimeData2$density_log, crimeData2$crmrte_log,main = "Log Density & Crime Rate" , 
     xlab = "Log of Density",ylab = "Log of Crime Rate",col="royalblue1")
text(crimeData2$density_log, crimeData2$crmrte_log, labels = crimeData2$county, cex=0.7, pos=3 , col = "red")
crimeData4 <- crimeData2[which(crimeData2$county!=173),]
cor(crimeData2$density_log, crimeData2$crmrte_log)
cor(crimeData4$density_log, crimeData4$crmrte_log)
cor(crimeData4$density, crimeData4$crmrte_log)
boxplot(density~urban, data=crimeData2 , main = "Box plot of crime rate")
cor(crimeData4$urban, crimeData4$density_log)
```


## Tax revenue per capita (taxpc)

The scatter plot indicates there may be a weak linear relationship between taxpc and crmrte_log.
The histogram of taxpc is skewed to the right, so we considered taking the log of taxpc.
However, the correlation between taxpc and crmrte_log (0.37) is slightly higher than the correlation between taxpc_log and crmrte_log (0.36).
```{r}
par(mfrow=c(1,2))
par(mar=c(4, 2, 2, 2))
plot(crimeData3$taxpc, crimeData3$crmrte_log,main = "Tax per capita & Log Crime Rate" , 
     xlab = "Tax per capita" , ylab = "Log of Crime Rate" , col="royalblue1")
hist(crimeData2$taxpc, main="Hist. of Tax Revenue",col = "royalblue1")
crimeData2$taxpc_log <- log(crimeData2$taxpc)
cor(crimeData2$taxpc, crimeData2$crmrte_log)
cor(crimeData2$taxpc_log, crimeData2$crmrte_log)
```


## If in western/central North Carolina

We created a variable, area, to categorize the area counties reside in. 
Area takes three values: West, Central, and Other.
The box plot shows that the mean and interquartile range of crmrte_log is very similar between Central and Other.
The crmrte_log for West area is lower than other areas.
In modeling, we can group "Central" and "Other" together and only add the variable "West" to the model. 
```{r}
crimeData2$area <- ifelse(crimeData2$west==1, "West", ifelse(crimeData2$central==1, "Central", "Other"))
boxplot(crmrte_log~area, data=crimeData2)
```

## Percent of minority in 1980 (pctmin80)

The scatter plot shows a weak linear relationship between log of crime rate and percent of minority.
Low correlation coefficient (0.3) also confirms that.
Also note that the percent of minority is highly negatively correlated with the indicator "west".
This indicates west counties have lower percentage of minority.
```{r}
plot(crimeData3$pctmin80_2, crimeData3$crmrte_log,main = "% Minority & Log crime rate" , 
     xlab = "% minority in 1980" , ylab = "Log of Crime Rate" , col="royalblue1")
cor(crimeData2$pctmin80_2, crimeData2$crmrte_log)
cor(crimeData2$pctmin80_2, crimeData2$west)
```

## Weekly wages

There are nine variables related to weekly wages in the data. 
They represent weekly wages in different industries. 
As the correlation matrix shows, most of the weekly wages variables are highly correlated except for wsta.
When building the model, we should avoid putting all the correlated variables in the model 
for the same reason pointed out in the density/urban section of the EDA.
We also noticed that log of crime rate has the strongest linear relationship with wfed with correlation coefficeint of 0.51.
```{r}
crimeData_temp1 <- crimeData2[,c("crmrte_log","wcon", "wtuc", "wtrd", "wfir", "wser", "wmfg", "wfed", "wsta", "wloc")]
corr_DenUr <- cor(crimeData_temp1, use="pairwise")
corrplot(corr_DenUr, method="square", addCoef.col="white")
```

## Offense mix: face-to-face/other (mix)

The scatter plot doesn't indicate a strong relationship between mix and log of crime rate.
The weak correlation coefficient (-0.15) also confirms that.
```{r}
plot(crimeData3$mix, crimeData3$crmrte_log,main = "Mix & Log crime rate",
     xlab="Log of crime rate",ylab="Mix", col="royalblue1")
cor(crimeData2$mix, crimeData2$crmrte_log)
```

## Percent young male (pctymle)

The scatter plot shows that the majority of counties have 5%-10% of young male. 
County 133 has significantly higher male percentage than the rest of counties.
Log of crime rate doesn't seem to vary by the percent of young male based on the scatter plot, 
which is also evidented by 0.27 correlation coefficient.
```{r}
par(mfrow=c(1,2))
plot(crimeData3$pctymle, crimeData3$crmrte_log,main = "% young M & Log crime rate",
     xlab="Log of crime rate",ylab="% of young male", col="blue")
plot(crimeData3$pctymle, crimeData3$crmrte_log,main = "% young M & Log crime rate",
     xlab="Log of crime rate",ylab="% of young male", col="blue")
text(crimeData2$pctymle, crimeData2$crmrte_log, labels = crimeData2$county, cex=0.7, pos=3,col = "red")
cor(crimeData2$pctymle, crimeData2$crmrte_log)
```

# Model Building 1

In the first model, we only include the four key variables we are interested in. They are probability of arrest, probability of conviction, probability of prison, average sentences. Based on the EDA above, we take the log of crime rate as our response variable and didn't find any transformation to be necessary for the four explanatory variables.
$$\log{(\text{Crime Rate})} = \beta_0 + \beta_1 \cdot (\text{prbarr}) + \beta_2 \cdot (\text{prbconv}) 
+ \beta_3 \cdot (\text{prbpris}) + \beta_4 \cdot (\text{avgsen})$$
```{r}
model1 <- lm(crmrte_log ~ prbarr+prbconv+prbpris+avgsen, data=crimeData2)
summary(model1)
coeftest(model1, vcov = vcovHC)
par(mfrow=c(2,2))
par(mar=c(2, 2, 2, 2))
plot(model1)
vif(model1)
bptest(model1)
ncvTest(model1)
par(mfrow=c(1,2))
hist(rstudent(model1), main="Histogram of Studentized Residuals", breaks=10, freq=FALSE)
curve(dnorm(x, mean=0, sd=1), col="red", lwd=2, add=TRUE)
qqPlot(rstudent(model1), main="QQ-Plot Studentized Residuals")
AIC(model1)
```
* CLM 1: A linear model  
    + The model is specified such that the dependent variable is a linear function of the explanatory variables.This assumption is satisfied.  
* CLM 2: Random sampling  
    + Each observation represents a county in North Carolina. Only a selection of counties are included in the data.Since we do not have knowledge how counties are selected, we cannot confirm the selection is random.  
* CLM 3: No perfect multicollinearity  
    + R would alert us if there is perfect multicollinearity among explanatory variables.  
    + The VIFs for all variables in the model are all less than 2, which suggests there are no high correlation among them. This assumption is satisfied.  
* CLM 4: Zero-conditional mean  
    + The red spline curve in the Residuals vs. Fitted plot is mostly flat except for the end points where the number of observations is small.  
    + In the Residuals vs. Leverage plot, no observations have Cook's distance greater than 1.This assumption is satistified.  
* CLM 5: Homoscedasticity  
    + In both Residuals vs. Fitted plot and Scale-Location plot, the variance of residuals is curve.
    + Breusch-Pagan test shows p-value is 0.451 implies homoscedascity and we fail to reject the null hypothesis.This assumption is likely satisfied.  
* CLM 6: Normality of residuals  
    + The histogram of studentized residuals is fairly normal ditributed albeit a bit light in the right tail.  
    + Q-Q plot shows most data points in the right tail are below the diagonal line, which also confirms a light right tail. 
    Overall, Q-Q plot doesn't deviate significantly from normality and most data points are within the confidence interval. This assumption is satisfied.  

## Evaluation of statistical and pratical significance

Model 1 shows:

* A 1 percent point increase in the probability of arrest decreases crime rate by 2.09 %, given that all other variables remain constant.  
* A 1 percent point increase in the probability of conviction decreases crime rate by 0.79 %, given that all other variables remain constant.  
AIC for model 1 is 102.

# Model Building 2

Based on EDA, we concludes that the following variables are highly correlated with the response variable,
with correlation coefficient greater than 0.3:  
prbarr, prbconv, density_log, west, and wfed.  
The variable "urban" and a few other weekly wages variables are excluded from the list above due to their higher correlation with other explanatory variables.  
The pairwise correlation table shows that log of density is highly correlated with federal employee wages. 
Since the proportion of federal employees in a county is small, this variable may not represent the wage characteristics of a county.
So we remove federal employee wages from the model.

$$\log{(\text{Crime Rate})} = \beta_0 + \beta_1 \cdot (\text{prbarr}) + \beta_2 \cdot (\text{prbconv}) 
+ \beta_3 \cdot (\text{log density}) + \beta_4 \cdot (\text{west})$$

Since the 79th observation (County 173) has Cook's distance greater than 1, we removed this observation from the model to eliminate undue influence.
```{r}
par(mfrow=c(1,2))
par(mar=c(2, 2, 2, 2))
crimeData_temp2 <- crimeData2[,c("crmrte_log","prbarr","prbconv", "density_log", "west", "wfed")]
corr_Model2 <- cor(crimeData_temp2, use="pairwise")
corrplot(corr_Model2, method="square", addCoef.col="white")

model2 <- lm(crmrte_log ~ prbarr+prbconv+density_log+west, data=crimeData2)
plot(model2, which=5)

crimeData5 <- crimeData2[which(crimeData2$county!=173),]

model2 <- lm(crmrte_log ~ prbarr+prbconv+density_log+west, data=crimeData5)
coeftest(model2, vcov = vcovHC)
par(mfrow=c(1,3))
par(mar=c(2, 2, 2, 2))
plot(model2, which=1)
plot(model2, which=3)
plot(model2, which=5)
vif(model2)
bptest(model2)
ncvTest(model2)
par(mfrow=c(1,2))
hist(rstudent(model2), main="Histogram of Studentized Residuals", breaks=10, freq=FALSE)
curve(dnorm(x, mean=0, sd=1), col="red", lwd=2, add=TRUE)
qqPlot(rstudent(model2), main="QQ-Plot Studentized Residuals")
AIC(model2)
```

## Assessment of the CLM assumptions 

* CLM 1: A linear model  
    + The model is specified such that the dependent variable is a linear function of the explanatory variables.  
    + This assumption is satisfied.  
* CLM 2: Random sampling  
    + Each observation represents a county in North Carolina. Only a selection of counties are included in the data.
    Since we do not have knowledge how counties are selected, we cannot confirm the selection is random.  
* CLM 3: No perfect multicollinearity  
    + R would alert us if there is perfect multicollinearity among explanatory variables.  
    + The VIFs for the four variables in the model are all less than 2, which suggests there are no high correlation among them. 
    + This assumption is satisfied.  
* CLM 4: Zero-conditional mean  
    + The red spline curve in the Residuals vs. Fitted plot is mostly flat except for the end points 
    where the number of observations is small.  
    + In the Residuals vs. Leverage plot, no observations have Cook's distance greater than 1.   
    + This assumption is satistified.  
* CLM 5: Homoscedasticity  
    + In both Residuals vs. Fitted plot and Scale-Location plot, the variance of residuals slightly increase then decrease
    when fitted values are between -4.5 and -2.5.  
    + Breusch-Pagan test shows significant p-value while the Score-test shows insignificant p-value.
    These tests are producing mixed evidence of homoscedasticity.  
    + This assumption is likely satisfied.  
    + If this assumption is not satisfied, the usual formulas for standard errors are inaccurate. 
    Heteroskedasticity-robust standard errors should be used to test the significance of the parameter estimates.  
* CLM 6: Normality of residuals  
    + The histogram of studentized residuals is fairly normal ditributed albeit a bit light in the right tail.  
    + Q-Q plot shows most data points in the right tail are below the diagonal line, which also confirms a light right tail. 
    Overall, Q-Q plot doesn't deviate significantly from normality and all data points are within the confidence interval.  
    + This assumption is satisfied.  

## Evaluation of statistical and pratical significance

All four explanatory variables are statistically significant.  
Model 2 shows:

* A 1 percent point increase in the probability of arrest decreases crime rate by 1.062%, given that all other variables remain constant.  
* A 1 percent point increase in the probability of conviction decreases crime rate by 0.58%, given that all other variables remain constant.  
* Density is a geographic control variable. A 1% increase in the density increases crime rate by 0.335%, given that all other variables remain constant.  
* Indicator "west" is also a geographic control variable. Western counties have 36.4% less crime rate, given that all other variables remain constant. 
All the parameter estimates are practically significant. 
Adding the two control variables improves the model. AIC decreases from 102 (Model 1) to 45 (Model 2).

# Model Building 3

For this model, we include all the variables that are not highly correlated.
```{r}

crimeData6 <- crimeData2[which(crimeData2$county!=173),]


model3 <- lm(crmrte_log ~ prbarr+prbconv+prbpris+avgsen+polpc_log+density_log+taxpc
             +west+central+mix+pctymle, data=crimeData6)
coeftest(model3, vcov = vcovHC)
par(mfrow=c(2,2))
par(mar=c(2, 2, 2, 2))
plot(model3)
#ols_plot_diagnostics(model3)
vif(model3)
bptest(model3)
ncvTest(model3)
par(mfrow=c(1,2))
hist(rstudent(model3), main="Histogram of Studentized Residuals", breaks=10, freq=FALSE)
curve(dnorm(x, mean=0, sd=1), col="red", lwd=2, add=TRUE)
qqPlot(rstudent(model3), main="QQ-Plot Studentized Residuals")
AIC(model3)
```
* CLM 1: A linear model  
    + The model is specified such that the dependent variable is a linear function of the explanatory variables.  This assumption is satisfied.  
* CLM 2: Random sampling  
    + Each observation represents a county in North Carolina. Only a selection of counties are included in the data.Since we do not have knowledge how counties are selected, we cannot confirm the selection is random.  
* CLM 3: No perfect multicollinearity  
    + R would alert us if there is perfect multicollinearity among explanatory variables.  
    + The VIFs for all variables in the model are all less than 2, which suggests there are no high correlation among them. This assumption is satisfied.  
* CLM 4: Zero-conditional mean  
    + The red spline curve in the Residuals vs. Fitted plot is mostly flat except for the end points where the number of observations is small.  
    + In the Residuals vs. Leverage plot, there is 1 observations have Cook's distance greater than 1.   This assumption is satistified.  
* CLM 5: Homoscedasticity  
    + In both Residuals vs. Fitted plot and Scale-Location plot, the variance of residuals remain flat with minor decrease and eventually increasing. Most points are
    when fitted values are between -5.0 and -2.5.  
    + Breusch-Pagan test shows p-value is 0.15 implies homoscedascity and we fail to reject the null hypothesis.
    These tests are producing mixed evidence of homoscedasticity. This assumption is likely satisfied.  
* CLM 6: Normality of residuals  
    + The histogram of studentized residuals is fairly normal ditributed albeit a bit light in the right tail.  
    + Q-Q plot shows most data points in the right tail are below the diagonal line, which also confirms a light right tail. 
    Overall, Q-Q plot doesn't deviate significantly from normality and most data points are within the confidence interval. This assumption is satisfied.  

## Evaluation of statistical and pratical significance

Model 3 shows:

* A 1 percent point increase in the probability of arrest decreases crime rate by 1.41 %, given that all other variables remain constant.  
* A 1 percent point increase in the probability of conviction decreases crime rate by 0.54 %, given that all other variables remain constant.  
Adding the these control variables improves the model. AIC decreases from 102 (Model 1) to 45 (Model 2) to 13 (Model 3)

# Model Display
```{r, results='asis'}
se.model1 = sqrt(diag(vcovHC(model1)))
se.model2 = sqrt(diag(vcovHC(model2)))
se.model3 = sqrt(diag(vcovHC(model3)))
stargazer(model1, model2, model3, type = "latex", 
          title = "Linear Models Predicting Log of Crime Rate",
          omit.stat="f",
          se=list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001),
          float=FALSE) 
```
The parameter estimates for the two key variables of interest are relatively robust.

* In all three models, the parameter estimate for the probability of arrest are negative and statistically significant.
The parameter estimates range from -2.10 to -1.06. 
The difference is mostly caused by the geographic control variables in the model.  
* In all three models, the parameter estimate for the probability of conviction are negative and statistically significant. 
The parameter estimates range from -0.80 to -0.51.
The difference is mostly caused by the geographic control variables in the model.  



# Omitted Variables

 We are interested in the relationship between prbarr and prbconv and our “omitted” variables mentioned below.
 1.) Education
 2.) Percentage of people using drug
 3.) Percentage of people are married with kids
 4.) Percentage of people who own guns
 5.) Percentage of smart mobile penetration
 
 Suppose our estimation model is represented by below equation , where A is prbarr and B is prbconv. 
 $\beta_0, \beta_1,\beta_2$  is the intercepts and coefficients of A (prbarr) and B (prbconv) respectively.  We can represent the Population regression as 

$$ Y (Population) = \beta_0+\beta_1A+\beta_2B $$

$$ Y (Estimated) = \alpha_0+\alpha_1A+\alpha_2B $$
$$ Y (Est Model1) = -2.92426013-2.09740014*prbarr -0.79654556*prbconv $$


# Omitted variable 1: Education
## Crime rate and Education are negatively correlated (NEGATIVE).
We estimate a negative correlation between Crime Rate and Education based on following logic and reasoning. We estimate that higher the education within the population then they are less likely to commit a crime. Another reason could be that educated people tend to understand the law better and are more likely to respect the law and less likely to commit crime.

##prbarr and Education are negatively correlated (NEGATIVE)
We estimate that educated people are more likely to be aware of their rights and they are more likely to avoid being wrongfully arrested , hence reduced arrest rates. Also police are less likely to believe an educated person committed the crime. Finally more educated people are more familiar with investigation methods and hence are less likely to leave less clues if they had committed the crime , leading to less likelihood of arrests. Hence we estimate that education and prbarr are negatively correlated.
$$\alpha_1 < 0$$
this is positive bias , alpha1 (estimated) = -2.1 = beta1 (true) + positive
$$\alpha(estimated)= -2.1 = \beta_1 (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in statistical significance.

##prbconv and Education are negatively correlated (NEGATIVE).
We estimate that higher education people are likely to have have higher income.People with higher income are more likely to afford better lawyers and legal help and are less likely to be convicted. Overall positive bias. 
$$\alpha_1 < 0$$
This is positive bias , alpha (estimated) = -0.8 = beta (true) + positive
$$\alpha(estimated)= -0.8 = \beta (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in statistical significance.

# Omitted variable 2: % of people using drug
## Crime rate and % of people using drug are positively correlated (POSITIVE).
We estimate a positive correlation between Crime Rate and % of people using drug based on following logic and reasoning. We estimate that people under the influence of drugs are more likely to commit a crime. 

##prbarr and % of people using drug are positively correlated (POSITIVE).
We estimate that drug addicts are easier to be found if they committed the crime leading to likelihood of higher arrests. Another reason could be that police are more likely to believe that drug addicts committed the crime.Finally the people consuming drugs are likely to consume drugs in groups and when police perform arrests they are likely to find other drug consuming people leading to higher arrests. Hence we estimate that % of people using drugs and prbarr are positively correlated.
$$\alpha_1 < 0$$
this is positive bias , alpha1 (estimated) = -2.1 = beta1 (true) + positive
$$\alpha(estimated)= -2.1 = \beta_1 (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in STATISTICAL significance.

##prbconv and % of people using drug are positively correlated (POSITIVE).
We estimate that % of people using drugs are likely to be spend all their money on drugs leading to poverty. People in poverty are less likely to get best legal help and are likely to have higher convition rates. Overall positive bias. 
$$\alpha_1 < 0$$
This is positive bias , alpha (estimated) = -0.8 = beta (true) + positive
$$\alpha(estimated)= -0.8 = \beta (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in STATISTICAL significance.

# Omitted variable 3: % of people are married with kids
## Crime rate and % of people are married with kids are negatively correlated (NEGATIVE).
We estimate a negative correlation between Crime Rate and % of people are married with kids based on following logic and reasoning. We estimate that married couples with kids to have more considerations for family and thus less likely to commit a crime.

##prbarr and % of people are married with kids are negatively correlated (NEGATIVE).
We estimate that people married with kids are unlikely to come forward as a witness of a crime (in worry of wellbeing of their family) with any information leading to reduced probability of arrest.
$$\alpha_1 < 0$$
this is positive bias , alpha1 (estimated) = -2.1 = beta1 (true) + positive
$$\alpha(estimated)= -2.1 = \beta_1 (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in STATISTICAL significance.

##prbconv and % of people are married with kids are negatively correlated (NEGATIVE).
We estimate that % of people are married with kids are expected to have less convitions since the judges are likely to keep in consideration impact on the family and kids of the conviction. 
$$\alpha_1 < 0$$
This is positive bias , alpha (estimated) = -0.8 = beta (true) + positive
$$\alpha(estimated)= -0.8 = \beta (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in STATISTICAL significance.

# Omitted variable 4: % of people who own guns
## Crime rate and % of people who own guns are positively correlated (POSITIVE).
We estimate a positive correlation between Crime Rate and % of people who own guns based on following logic and reasoning. With more people owning guns , small alterations / conflicts can lead to gun fight leading to higher rates of crime.

##prbarr and % of people who own guns are positively correlated (POSITIVE).
We estimate that people who are gun owners are more likely to involved in shooting related crimes. We estimate that since the guns and gun owners are more likley to easily tracked this can lead to higher probability of arrests.
$$\alpha_1 < 0$$
this is positive bias , alpha1 (estimated) = -2.1 = beta1 (true) + positive
$$\alpha(estimated)= -2.1 = \beta_1 (true)+(positive) $$
True Coefficent is even more negative what is estimated and hence increase in STATISTICAL significance.

##prbconv and % of people who own guns are negatively correlated (NEGATIVE).
We estimate that % of people who own guns are expected to richer than others and hence more likely to afford better lawyers and legal help. this can lead to less conviction rates. 
$$\alpha_1 < 0$$
This is positive bias , alpha (estimated) = -0.8 = beta (true) + negative
$$\alpha(estimated)= -0.8 = \beta (true)+(negative) $$
True Coefficent is less negative what is estimated and hence loose STATISTICAL significance.


# Omitted variable 5: % of smart mobile penetration
## Crime rate and % of smart mobile penetration are positively correlated (POSITIVE).
We estimate a positive correlation between Crime Rate and % of smart mobile penetration based on following logic and reasoning. With higher smart phone users are more likely to use better communication methods via encrypted apps for committing the crime , hence increasing the likelihood of crime rates. Another possible reason can be that smart phones themselves are expensive devices and with higher smart phones in a county can lead to higher theft cases of smart phones itself , hence increasing crime rates.

##prbarr and % of smart mobile penetration are negatively correlated (NEGATIVE).
We estimate that people using smart phone are more likely to use encrypted apps on the smart phones for communication for committing the crime. Since these encrypted application are extremely difficult to track and hence leading to reduced arrest rates.
$$\alpha_1 < 0$$
this is less negative bias , alpha1 (estimated) = -2.1 = beta1 (true) + negative
$$\alpha(estimated)= -2.1 = \beta_1 (true)+(negative) $$
prbarr has less impact on the log of crime rate (lose statistical significance)

##prbconv and % of smart mobile penetration are negatively correlated (NEGATIVE).
We estimate that  smart phone has higher protection (such as iPhone), which are harder to crack by police , hence reducing the conviction rates. Also we estimate that not all police departments are good at dealing with digital evidence and hence leading to reduced conviction rates.

$$\alpha_1 < 0$$
this is less negative bias , alpha (estimated) = -0.8 = beta (true) + negative
$$\alpha(estimated)= -0.8 = \beta (true)+(negative) $$
prbconv has less impact on the log of crime rate (lose statistical significance).



# Conclusion
Our models show that an increase in the probability of arrest and/or an increase in the proability of conviction reduces the crime rate. On the other hand, there are no statistically significance relationships between the severity of punishment (the probability of prison and average sentences) and crime rate. This conclusion is robust and is not sensitive to modeling specifications. We believe the key to reduce crime rates is to be effective in apprehending criminals. We recommend community service as part of the punishment to help rehabilitate criminals rather than increasing their sentences. We recommend increasing investment in effective policing and public infrustrcture for conviction and reducing spending on prison expansion.
